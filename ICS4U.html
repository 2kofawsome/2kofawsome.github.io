<!DOCTYPE html>
<html lang="en-US">

<head>
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-124907739-1"></script>
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());
		gtag('config', 'UA-124907739-1');
	</script>
	<title>ICS4U Timeline</title>
	<meta charset="UTF-8" name="viewport" content="width=1024">
	<link rel="stylesheet" type="text/css" href="StyleSheetICS4U.css">
</head>

<body>

<div id="deskShow">
<div class="fill">
<ul>
	<li><a class="desk" href="#TAstats">Project: TA Stats Webpage</a></li>
	<li><a class="desk" href="#workSchedule">Project: Work Schedule</a></li>
	<li><a class="desk" href="#periodicNames">Project: Periodic Names</a></li>
	<li><a class="desk" href="#twitterBot">Project: Twitter Bot</a></li>
	<li><a class="desk" href="#machineLearning">Project: Machine Learning</a></li>
</ul>
</div>

<iframe width="100%" height="400" src="https://time.graphics/embed?v=1&id=177113" frameborder="0" allowfullscreen></iframe>

</div>

<div id="mobileShow">
<div class="fill">
<ul>
	<li><a class="mobile" href="#TAstats">TA Stats Webpage</a></li>
	<li><a class="mobile" href="#workSchedule">Work Schedule</a></li>
	<li><a class="mobile" href="#periodicNames">Periodic Names</a></li>
	<li><a class="mobile" href="#twitterBot">Twitter Bot</a></li>
	<li><a class="mobile" href="#machineLearning">Machine Learning</a></li>
</ul>
</div>

<iframe width="100%" height="300" src="https://time.graphics/embed?v=1&id=177113" frameborder="0" allowfullscreen></iframe>

</div>

<div class="fill" id="deskSummaryChart"></div>

<div>
	<br>
	<h1>Projects</h1>
	<h2 id="TAstats">TA Stats Webpage:</h2>
	<h3>-Components</h3>
	<p>Script (Python): Using Python files to scrap the webpages of TrueAchievements.com and collect the needed information (beautifulsoup and requests) then editing text files to easily display that data to be copied and pasted over to JSON format for the webpage</p>
	<p>Framework (HTML/CSS): Using webpage design (starting from close to square 1) created a "shell" website that would displays the data</p>
	<p>Graphs (JavaScript): Using javascript (and fusioncharts) created graphs that could easily be altered by changing json data to display</p>
	<p>Graphic touches (JavaScript/HTML/CSS): Created javascript programs that could change the look (CSS) and data (HTML) at a click</p>
	<h3>-Notes</h3>
	<p>This website was created to display information and statistics from an Xbox achievement competition I was in for 4 weeks. Although no one seemed to notice the work that went into the website, I did start getting called "the stats guy" so that's cool!</p>
	<h3>-Download Link:</h3>
	<a href="https://docs.google.com/uc?export=download&id=1nM5ewBnDTIA2nQS6TrLtgcoLZnEjkibY">Download Link</a>
	<br>
	<br>
	
	<hr id="workSchedule">
	
	<h2>Work Schedule:</h2>
	<h3>-Components</h3>
	<p>Script (Python): Using selenium and chromedriver in a script to log into my employers website, then using beautifulsoup and request to collect the html info and find my schedule, once schedule is collected using smtplib to send an "email" of the shifts which redirects to my phone number</p>
	<p>Automation (Linux): On the Raspberry Pi learned how to use Crontab to fully automate the script every morning</p>
	<h3>-Notes</h3>
	<p>Although not the longest piece of code I have ever wrote (clocks in at 100 lines), I learned many new features and this was the first use of my Raspberry Pi! It also has a real world use and makes my life easier.</p>
	<h3>-Download Link:</h3>
	<a href="https://docs.google.com/uc?export=download&id=1HgeCRGEJ9LQxIz_nFD0xvgnJ-0Xjf3uZ">Download Link</a>
	<br>
	<br>
	
	<hr id="periodicNames">
	
	<h2>Periodic Names:</h2>
	<h3>-Components</h3>
	<p>Script (Python): A script that loops a function to find all possible ways to recreate a string with element symbols from the periodic table. If every letter in the string cannot be created, will loop to find the best possible</p>
	<h3>-Notes</h3>
	<p>A nice multi-hour grind lead to this piece of code, nothing spectacular, but worth mentioning.</p>
	<h3>-Download Link:</h3>
	<a href="https://docs.google.com/uc?export=download&id=1sWCxBtlrzs97NKxeNCMMbn1aFCC_Qj1b">Download Link</a>
	<br>
	<br>
	
	<hr id="twitterBot">
	
	<h2>Twitter Bot:</h2>
	<h3>-Components</h3>
	<p>Image Isolation (Python, Manual): A python script using beautifulsoup and request is able to collect the html and remove many of the posted images that are not good, reducing to about 50%. I then manually go through and choose 365 of those to post (posts each day)</p>
	<p>Creating Database (Python/SQL): </p>
	<p>Image Manipulation (Python): </p>
	<p>Posting to Twitter (Python): </p>
	<p>Automation (Linux): </p>
	<p>New Posts (Python): </p>
	<h3>-Notes</h3>
	<p>-</p>
	<h3>-Download Link:</h3>
	<a href="https://2kofawsome.github.io/ICS4U">Not done</a>
	<br>
	<br>
	
	<hr id="machineLearning">
	
	<h2>Machine Learning:</h2>
	<h3>-Components</h3>
	<p>Unknown</p>
	<h3>-Notes</h3>
	<p>-</p>
	<h3>-Download Link:</h3>
	<a href="https://2kofawsome.github.io/ICS4U">Not done</a>
</div>

<br>
<br>
<br>

<address>
	Sam Gunter<br> 
	2k of awsome<br>
	samgunter12@gmail.com<br><br>
</address>
</body>
</html>